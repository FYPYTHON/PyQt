1¡¢ÏÂÔØ
https://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.4.0/
kafka_2.13-2.4.0.tgz    
tar -xzf kafka_2.12-2.4.0.tgz
cd kafka_2.12-2.4.0

2¡¢start server
zk:
bin/zookeeper-server-start.sh config/zookeeper.properties
kafka:
bin/kafka-server-start.sh config/server.properties

server.properties: remote addr
      advertised.listeners=PLAINTEXT://192.168.196.129:9092

3¡¢create a topic
topic name: test
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test
show topic:
bin/kafka-topics.sh --list --bootstrap-server localhost:9092
ads.h323 
delete a topic:
./bin/kafka-topics.sh --delete --bootstrap-server localhost:9092 --topic kptest
>>test

# 分区扩容
./kafka-topics.sh --zookeeper 127.0.0.1:2181 -alter --partitions 4 --topic test

4¡¢send messages
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test

5¡¢start a consumer
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic ods.h323 --from-beginning

6¡¢Setting up a multi-broker cluster
> cp config/server.properties config/server-1.properties
> cp config/server.properties config/server-2.properties
config/server-1.properties:
    broker.id=1
    listeners=PLAINTEXT://:9093
    log.dirs=/tmp/kafka-logs-1
 
config/server-2.properties:
    broker.id=2
    listeners=PLAINTEXT://:9094
    log.dirs=/tmp/kafka-logs-2

> bin/kafka-server-start.sh config/server-1.properties &
...
> bin/kafka-server-start.sh config/server-2.properties &

> bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 3 --partitions 1 --topic my-replicated-topic

> bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic my-replicated-topic

> bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic test

publish:
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic
consume:
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic my-replicated-topic

kill:
ps aux | grep server-1.properties
wmic process where "caption = 'java.exe' and commandline like '%server-1.properties%'" get processid


7¡¢Use Kafka Connect to import/export data
echo -e "foo\nbar" > test.txt
> bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties

> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning


v59ab8

抓所有src dst port为1719 1759 1720 1760的包
抓收的包，目的端口是60100-62100。发的包，源端口为60100-62100
问下，这个语句tcpdump怎么写的
tcpdump -i any port 1719 or port 1759 or port 1720 or port 1760  or dst portrange 60100-62100 or src portrange 60100-62100 -i any -s 0 -G 1800 -Z root -n -B 102400 -w %Y_%m%d_%H%M_%S.pcap &

tcpdump port 1719 or port 1759 or port 1720 or port 1760 or dst portrange 60100-62100 or src portrange 60100-62100 -i any -s 0 -G 1800 -Z root -n -B 102400 -w %Y_%m%d_%H%M_%S.pcap &
这样应该没问题吧，上次说的还是有丢包情况

kdfs 文件服务/  王国强/吴凯
h323parse h323协议解析  王国强/王国强
OpsReceiver   平台/终端媒体信息采集  王国强/谢金鑫


ZOOKEEPER Will not attempt to authenticate using SASL (unknown error)


删除zoo.cfg里面配置dataDir=日志存储路径中version-2，即可解决

